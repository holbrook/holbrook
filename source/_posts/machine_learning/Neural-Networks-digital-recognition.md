---
title: 用神经网络识别手写数字
postslug: Neural-Networks-digital-recognition
date: 2018-02-23
category: 机器学习
tags: 神经网络, 计算机视觉
---

本文主要参考[74行代码实现手写数字识别](http://www.cvvision.cn/1975.html)，
但是没有采用Michael Nielsen的[neural-networks-and-deep-learning](https://github.com/mnielsen/neural-networks-and-deep-learning)代码，而是直接使用scikit-learn的MLPClassifier(Multi-layer Perceptron Classifier, 多层感知机分类器)。
数据来自著名的MNIST数据集。

<!--more-->

本文的代码需要如下python模块：

- matplotlib
- PIL(pillow)
- numpy
- scikit-learn
- scipy
- Theano

# 神经网络建模的一般过程

神经网络分析的一般过程为：导入数据，训练模型，优化模型，启发式理解等。如下图:

{% asset_img general_process_of_neural_networks.jpg 神经网络分析的一般过程 %}

用神经网络解决数字识别问题的思路就是：

1. 获取大量的手写数字的图像，并且已知它们表示的是哪个数字
2. 以此为训练样本集合，自动生成一套神经网络模型
3. 依靠它来识别新的手写数字

## 生成模型

{% asset_img gen_model.jpg 生成模型 %}

生成模型是这样一个逐步确定未知参数的迭代过程：

1. 选定一个基础模型
2. 设定初始化参数代入模型
3. 用训练集对模型进行训练
4. 通过一些数量指标，评估训练误差
5. 如果训练误差不满足要求，继续调整参数
6. 重复3--5

生成的模型只是对训练集表现较好，为了验证模型的有效性，还需要通过与训练集无关的测试集，对模型进行检验。


## 筛选模型

如果有多个模型，要从中选出最好的，很自然的思路就是让多个模型跑测试集，从中挑出误差最小的。
但这种思路有一个明显的问题：如果把模型编号作为一个参数，上述过程就相当于用测试集进行训练。

如果从多个模型的角度来看，有一些“决定模型”的参数，比如训练次数、梯度下降过程的步长、规范化参数、学习回合数、minibatch 值等等，我们把他们叫做超参数。
超参数是更高层次的，模型框架的参数，可以理解成参数的参数。

为了确定超参数，可以把数据再分出一部分，叫做“交叉验证集”。经过交叉验证的模型，依然不能保证在新的数据继续有效，
所以最后还是需要一个新的测试集对模型进行考核评价。

筛选模型，就是确定“超参数”的过程。

{% asset_img select_model.jpg 筛选模型 %}

至此，规范的方法的是将数据集拆分成三个集合：训练集、交叉验证集、测试集，
依次训练参数、超参数，最终得到最优的模型。

这是一个反复迭代不断优化的过程。其中很大一部分工作是在调整参数和超参数。

需要注意的是，在调优超参数时，一定要将多个模型用交叉验证集的结果来横向比较，
选出最优模型后再用一个新的测试集来最终评估该模型。
绝对不能直接用测试集进行调优，否则很容易发生`过拟合`.

# 问题建模

回到手写数字识别的问题。以三层(单隐层)神经网络为例：

{% asset_img three_layer.jpg 三层神经网络 %}

- 输入层：将每个图片规整到28*28=784个像素。 每个节点可以输入0--255（像素点的灰度）
- 输出层：0-9这10个数字。每个节点可以输出0或1
- 中间层：用n个节点进行处理，其中n是超参数


# 代码

##数据探索

{% asset_ipynb data_explore.ipynb %}

## 训练

这里省去了优化参数的过程。

{% asset_ipynb training.ipynb %}

## 交叉验证

用交叉验证工具，可以根据score，优化模型的各个参数。

{% asset_ipynb cross_validate.ipynb %}


